# 新機能追加 - Tech Mentor 音声文字起こしアプリ

## 🎯 追加された機能

### 1. 🎙️ 音声修正機能
**ファイル**: `utils/voice_commands.py`, `app.py` (tab4)

#### 機能概要
- 音声で文字起こし結果を修正・編集
- 音声コマンドの自動認識と解析
- リアルタイム音声処理

#### 対応コマンド
- **修正**: 「〇〇を△△に修正」
- **削除**: 「〇〇を削除」
- **追加**: 「〇〇を追加」
- **要約**: 「要約して」
- **箇条書き**: 「箇条書きにして」

#### 使用方法
1. 録音タブで文字起こしを実行
2. 音声修正タブに移動
3. 「音声コマンドを聞き取る」ボタンを押下
4. 音声で指示を発声
5. 自動解析されたコマンドを確認・実行

#### 技術仕様
- **音声認識**: Google Speech Recognition API
- **Whisper**: OpenAI Whisper モデル
- **コマンド解析**: キーワードベースの自然言語処理
- **処理時間**: 約5秒間の音声聞き取り

### 2. 📚 ユーザー辞書機能
**ファイル**: `utils/user_dictionary.py`, `pages/user_dictionary.py`

#### 機能概要
- カスタム用語・略語の管理
- カテゴリ別辞書エントリ
- 検索・エクスポート機能

#### 主要機能
- **カテゴリ管理**: 技術用語、略語、カスタム
- **エントリ管理**: 単語、定義、例文
- **検索機能**: 単語・定義・例文での検索
- **インポート/エクスポート**: JSON、TXT形式

#### 使用方法
1. ユーザー辞書タブまたは専用ページにアクセス
2. カテゴリを追加
3. エントリを追加（単語、定義、例文）
4. 検索・編集・削除

#### データ構造
```json
{
  "categories": {
    "技術用語": {
      "description": "技術関連の用語",
      "entries": {
        "API": {
          "definition": "Application Programming Interface",
          "examples": ["REST API", "GraphQL API"],
          "created_at": "2024-01-01T00:00:00",
          "last_updated": "2024-01-01T00:00:00"
        }
      }
    }
  },
  "metadata": {
    "created_at": "2024-01-01T00:00:00",
    "last_updated": "2024-01-01T00:00:00",
    "total_entries": 1
  }
}
```

### 3. ⚡ コマンド機能
**ファイル**: `utils/command_processor.py`, `pages/commands.py`

#### 機能概要
- LLM指示による文字起こし結果の加工
- カスタムコマンドの作成・管理
- ファイル出力機能

#### デフォルトコマンド
1. **箇条書き**: 文字起こし結果を箇条書きに変換
2. **要約**: 文字起こし結果を要約
3. **テキストファイル出力**: 整理されたテキストファイル形式
4. **LLM要約ファイル出力**: 構造化された要約ファイル
5. **キーポイント抽出**: 重要なポイントを抽出
6. **アクションアイテム抽出**: タスク項目を抽出

#### 使用方法
1. コマンド管理ページにアクセス
2. 文字起こし履歴から選択または直接テキスト入力
3. 実行したいコマンドを選択
4. コマンド実行
5. 結果の確認・ファイル保存

#### カスタムコマンド作成
- **コマンド名**: 実行時の識別名
- **説明**: 機能の説明
- **LLMプロンプト**: `{text}`で文字起こし結果を参照
- **出力形式**: 定義済み形式またはカスタム

#### 出力形式
- `bullet_points`: 箇条書き
- `summary`: 要約
- `text_file`: テキストファイル形式
- `llm_summary_file`: LLM要約ファイル形式
- `key_points`: キーポイント
- `action_items`: アクションアイテム

## 🔧 技術アーキテクチャ

### ファイル構成
```
sample_project1/
├── app.py                          # メインアプリケーション
├── pages/
│   ├── user_dictionary.py          # ユーザー辞書管理ページ
│   ├── commands.py                 # コマンド管理ページ
│   ├── transcription_results.py    # 文字起こし結果管理
│   ├── dictionary.py               # 既存辞書機能
│   ├── summary.py                  # 既存要約機能
│   └── settings.py                 # 既存設定機能
├── utils/
│   ├── voice_commands.py           # 音声コマンド処理
│   ├── user_dictionary.py          # ユーザー辞書管理
│   ├── command_processor.py        # コマンド処理
│   ├── transcription_manager.py    # 文字起こし管理
│   └── transcribe_utils.py         # 文字起こしユーティリティ
├── settings/
│   ├── user_dictionary.json        # ユーザー辞書データ
│   ├── commands.json               # コマンド設定
│   └── transcription_history.json  # 文字起こし履歴
└── outputs/                        # コマンド実行結果ファイル
```

### 依存関係
```txt
streamlit
streamlit-webrtc
whisper
openai-whisper
pyaudio
numpy
scipy
librosa
av
SpeechRecognition
```

## 🚀 セットアップ手順

### 1. 依存関係のインストール
```bash
pip install -r requirements.txt
```

### 2. 音声認識の設定
- Google Speech Recognition APIを使用
- インターネット接続が必要
- マイク権限の許可が必要

### 3. Whisperモデルの準備
- 初回実行時に自動ダウンロード
- モデルサイズ: base（推奨）
- ダウンロード時間: 約1-2分

### 4. アプリケーション起動
```bash
streamlit run app.py
```

## 📖 使用方法

### 基本的なワークフロー
1. **録音**: 録音タブで音声を録音・文字起こし
2. **修正**: 音声修正タブで音声コマンドによる修正
3. **辞書**: ユーザー辞書で専門用語を管理
4. **コマンド**: コマンド機能で結果を加工
5. **管理**: 各機能ページで詳細管理

### 音声修正の例
```
音声入力: "技術用語を専門用語に修正"
解析結果: コマンド=修正, 内容=技術用語を専門用語に
実行結果: "技術用語" → "専門用語" に置換
```

### コマンド実行の例
```
入力: 文字起こし結果
コマンド: 箇条書き
出力: 
• 項目1
• 項目2
• 項目3
```

## 🔍 トラブルシューティング

### 音声認識の問題
- **マイク権限**: ブラウザのマイク権限を確認
- **音声レベル**: 適切な音量で発声
- **ネットワーク**: インターネット接続を確認
- **ブラウザ**: Chrome推奨

### Whisperモデルの問題
- **ダウンロード失敗**: ネットワーク接続を確認
- **メモリ不足**: モデルサイズを小さく設定
- **初回起動遅延**: モデルダウンロード完了まで待機

### ファイル保存の問題
- **権限エラー**: 出力ディレクトリの書き込み権限を確認
- **ディスク容量**: 十分な空き容量を確保
- **文字エンコーディング**: UTF-8で保存

## 🔮 今後の拡張予定

### 短期目標
- [ ] LLM統合（OpenAI API、Claude API）
- [ ] 音声コマンドの精度向上
- [ ] バッチ処理機能
- [ ] 音声ファイルの直接アップロード

### 中期目標
- [ ] リアルタイム音声認識
- [ ] 多言語対応
- [ ] 音声合成機能
- [ ] クラウド同期

### 長期目標
- [ ] AI要約の高度化
- [ ] 音声翻訳機能
- [ ] 会議録音自動化
- [ ] 音声データベース構築

## 📞 サポート

### よくある質問
**Q: 音声認識がうまく動作しません**
A: マイク権限、音量、ネットワーク接続を確認してください。

**Q: Whisperモデルのダウンロードに時間がかかります**
A: 初回のみです。ネットワーク環境によって1-5分程度かかります。

**Q: コマンドの結果が期待と異なります**
A: LLM統合前のため、基本的な処理のみ対応しています。

### バグ報告
- GitHub Issuesで報告
- 再現手順の詳細記載
- 環境情報（OS、ブラウザ、バージョン）

### 機能要望
- 新機能の提案は歓迎
- 実装可能性を考慮
- 優先度の高いものから対応 